# Barebones template to ensure pipeline is triggered
include:
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: '37d84c8a56036de2567f88f7ede7557566d3cb53' 
    file: 'environments/devex.yml'
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: '37d84c8a56036de2567f88f7ede7557566d3cb53'  
    file: 'blocks/aws.yml'
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: '37d84c8a56036de2567f88f7ede7557566d3cb53'
    file: 'blocks/docker.yml'

variables:
  ARTIFACT_NAME: "metaflow_integration_testing"
  MAJOR_VERSION: "1"
  MINOR_VERSION: "0"
  ARTIFACTORY_WEB_APP_URL: https://artifactory.zgtools.net/artifactory/webapp/#/packages/docker
  _IMAGE_TAG_FILE: 'image_tag_file.txt'

.generate_docker_image_version:
  script: &generate-docker-image-version-script
  - |
    if [ -z "${DOCKER_REPO_URL}" ] || [ -z "${MAJOR_VERSION}" ] || [ -z "${MINOR_VERSION}" ]; then
      echo "No DOCKER_REPO_URL=${DOCKER_REPO_URL}, MAJOR_VERSION=${MAJOR_VERSION} or MINOR_VERSION=${MINOR_VERSION} provided."
      exit 1
    fi
  - IMAGE_TAG="${MAJOR_VERSION}.${MINOR_VERSION}.${CI_COMMIT_SHORT_SHA}.${CI_COMMIT_REF_SLUG}"
  - |
    # Unfortunately we require gawk for a number of commands, but mawk is typically installed by default and has different substr behaviour.
    awk_version=$(awk -W version | sed -n 1p | awk '{print $1}')
    offset=$(if [ "${awk_version}" == "GNU" ]; then echo 1; else echo 0; fi)
    # Grab the team name from the closest Gitlab group to the Artificial Intelligence umbrella group.
    DEFAULT_TEAM_NAME=$(echo $CI_PROJECT_PATH | awk -v offset=$offset '{ split($0,parts,"/artificial-intelligence/");print substr(parts[2],0,index(parts[2],"/")-offset) }')
    IMAGE_PATH=${ARTIFACT_NAME:-$CI_PROJECT_NAME}
    if [ ! -z "${TEAM_NAME}" ] || [ ! -z "${DEFAULT_TEAM_NAME}" ]; then
      # Only if we have successfully found a team name should we construct a path using it.
      IMAGE_PATH=${TEAM_NAME:-$DEFAULT_TEAM_NAME}/${IMAGE_PATH}
    fi
  - export IMAGE_REPOSITORY=${DOCKER_REPO_URL}/${ORGANIZATION_NAME}/${IMAGE_PATH}
  - export IMAGE_REPOSITORY_TAG=${IMAGE_REPOSITORY}:${IMAGE_TAG}
  artifacts: &generate-docker-image-version-artifacts
    paths:
    - versions
    expire_in: "6 months"

.build_push_docker_image:
  # extends: .read_docker_image_version
  script: &build-push-docker-image
  - |
    catch() {
      # Temporarily disable xtrace output since that messes up our capturing of logs.
      # Dump the logs for this check /dev/null so this is an invisible command to the user.
      {
          xtrace_enabled="${-//[^x]/}"
          if [ ! -z "${xtrace_enabled}" ]; then
              set +x
          fi
      } 2>/dev/null

      eval "$({
        __2="$(
          { __1="$("${@:4}")"; } 2>&1;
          ret=$?;
          printf '%q=%q\n' "$2" "$__1" >&2;
          exit $ret
        )"
        ret="$?";
        # One change we've made is to also capture the return code in a separate variable.
        printf '%s=%q\n' "$1" "$ret" >&2;
        printf '%s=%q\n' "$3" "$__2" >&2;
        printf '( exit %q )' "$ret" >&2;
      } 2>&1 )";

      {
          ret = "$?"
          if [ ! -z "${xtrace_enabled}" ]; then
              set -x
          fi
          return $ret
      } 2>/dev/null
    }
  - |
    if [ -z "${DOCKER_USERNAME}" ] || [ -z "${DOCKER_REPO_URL}" ] || [ -z "${DOCKER_API_KEY}" ]; then
      echo "No DOCKER_USERNAME=${DOCKER_USERNAME}, DOCKER_REPO_URL=${DOCKER_REPO_URL}) or len(DOCKER_API_KEY)=${#DOCKER_API_KEY} provided."
      exit 1
    fi
  - docker build --no-cache -f metaflow/plugins/kfp/dockerfiles/integration_testing_full_image/Dockerfile -t integration_testing_full_image .
  - echo ${DOCKER_API_KEY} | docker login --username ${DOCKER_USERNAME} --password-stdin ${DOCKER_REPO_URL}
  - docker tag integration_testing_full_image ${IMAGE_REPOSITORY_TAG}
  - echo ${IMAGE_REPOSITORY_TAG} > ${_IMAGE_TAG_FILE}
  - |
    catch ret stdout stderr \
      docker push ${IMAGE_REPOSITORY}
  - echo "${stderr}"
  - echo "${stdout}"
  - echo "HELLO"
  - echo "${ret}"
  - |
    if [ $RET -ne 0 ] && [[ $STDERR == *"manifest invalid"* ]]; then
        exit $RET
    fi
   
.path_to_host_file_directory: # obtains the path to file on the host machine, which is needed to mount a Docker on Docker
  script: &path-to-host-file-directory
  - export CONTAINER_ID=$(docker ps -q -f "label=com.gitlab.gitlab-runner.job.id=$CI_JOB_ID" -f "label=com.gitlab.gitlab-runner.type=build")
  - export MOUNT_NAME=$(docker inspect $CONTAINER_ID -f "{{ range .Mounts }}{{ if eq .Destination \"/builds\" }}{{ .Source }}{{end}}{{end}}")
  - export SHARED_PATH=$MOUNT_NAME/$CI_PROJECT_PATH
  
build:
  stage: build
  script:
    - *generate-docker-image-version-script
    - *build-push-docker-image
    # - export BUILT_IMAGE_FULL_PATH=${DOCKER_REPO_URL}/${_NAMED_VERSION_DOCKER_IMAGE_NAME}:${_NAMED_VERSION_DOCKER_IMAGE_TAG}
    # - echo ${BUILT_IMAGE_FULL_PATH} > ${_IMAGE_TAG_FILE} # file _IMAGE_TAG_FILE contains the path to the image
  artifacts:
    paths:
      - ${_IMAGE_TAG_FILE} # we pass this file as an artifact to be read in the testing stages

test:internal:
  extends: 
    - .devex_internal_eks # sets up AWS environment variables
    - .generate_kubeconfig # creates the .kube directory for the appropriate cluster
  variables:
    GIT_STRATEGY: none
    PIPELINE_VERSION: "1.0"
  stage: test
  script:
    - *path-to-host-file-directory
    - export BUILT_IMAGE_FULL_PATH=$( cat ${_IMAGE_TAG_FILE} ) # reading the path to the Docker image on Artifactory
    - cp -r /root/.kube .
    - docker run 
        -v ${SHARED_PATH}/.kube:/home/zservice/.kube
        --rm 
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID 
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY 
        -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN 
        -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION 
        ${BUILT_IMAGE_FULL_PATH}
        bash -c "
          export KFP_RUN_URL_PREFIX=https://kubeflow.corp.dev-k8s.zg-aip.net/ && 
          export KFP_SDK_NAMESPACE=metaflow-integration-testing && 
          export METAFLOW_DATASTORE_SYSROOT_S3=s3://aip-example-dev/metaflow/ && 
          export METAFLOW_USER=${GITLAB_USER_EMAIL} &&
          cd /home/zservice/metaflow/metaflow/plugins/kfp/tests && 
          python -m pytest -s -n 2 run_integration_tests.py --image ${BUILT_IMAGE_FULL_PATH}
        "

test:nonprod:
  extends: 
    - .devex_nonprod_eks
    - .generate_kubeconfig
  variables:
    GIT_STRATEGY: none
    PIPELINE_VERSION: "1.0"
  stage: test
  script:
    - *path-to-host-file-directory  
    - export BUILT_IMAGE_FULL_PATH=$( cat ${_IMAGE_TAG_FILE} )
    - cp -r /root/.kube .
    - docker run
        -v ${SHARED_PATH}/.kube:/home/zservice/.kube 
        --rm
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID 
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY 
        -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN 
        -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION 
        ${BUILT_IMAGE_FULL_PATH}
        bash -c "
          export KFP_RUN_URL_PREFIX=https://kubeflow.corp.stage-k8s.zg-aip.net/ && 
          export KFP_SDK_NAMESPACE=metaflow-integration-testing-dev && 
          export METAFLOW_DATASTORE_SYSROOT_S3=s3://aip-example-stage/metaflow/ && 
          export METAFLOW_USER=${GITLAB_USER_EMAIL} &&
          cd /home/zservice/metaflow/metaflow/plugins/kfp/tests && 
          python -m pytest -s -n 2 run_integration_tests.py --image ${BUILT_IMAGE_FULL_PATH}
        "

test:prod:
  extends: 
    - .devex_prod_eks
    - .generate_kubeconfig
  variables:
    GIT_STRATEGY: none
    PIPELINE_VERSION: "1.0"
  stage: test
  script:
    - *path-to-host-file-directory
    - export BUILT_IMAGE_FULL_PATH=$( cat ${_IMAGE_TAG_FILE} )
    - cp -r /root/.kube .
    - docker run
        -v ${SHARED_PATH}/.kube:/home/zservice/.kube 
        --rm
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID 
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY 
        -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN 
        -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION  
        ${BUILT_IMAGE_FULL_PATH}
        bash -c "
          export KFP_RUN_URL_PREFIX=https://kubeflow.corp.prod-k8s.zg-aip.net/ && 
          export KFP_SDK_NAMESPACE=metaflow-integration-testing-prod && 
          export METAFLOW_DATASTORE_SYSROOT_S3=s3://aip-example-prod/metaflow/ &&
          export METAFLOW_USER=${GITLAB_USER_EMAIL} && 
          cd /home/zservice/metaflow/metaflow/plugins/kfp/tests && 
          python -m pytest -s -n 2 run_integration_tests.py --image ${BUILT_IMAGE_FULL_PATH}
        "